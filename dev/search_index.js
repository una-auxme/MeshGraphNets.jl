var documenterSearchIndex = {"docs":
[{"location":"training_data/#Training-Data","page":"Training Data","title":"Training Data","text":"","category":"section"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"If you want to train your own network via MeshGraphNets.jl you have to provide your data files and a corresponding metadata file in a specific manner. This section describes the structure of those files.","category":"page"},{"location":"training_data/#Folder-Structure","page":"Training Data","title":"Folder Structure","text":"","category":"section"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"Your files have to be placed inside the same folder so that MeshGraphNets.jl can find them. The structure of your files should for example look like this:","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"- data\n    - datasets\n        - meta.json\n        - test.h5 (or test.tfrecord)\n        - train.h5 (or train.tfrecord)\n        - valid.h5 (or valid.tfrecord)","category":"page"},{"location":"training_data/#Files-for-Training,-Evaluation-and-Testing","page":"Training Data","title":"Files for Training, Evaluation and Testing","text":"","category":"section"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"For each of the steps a separate file has to be provided (see Folder Structure). It is recommended to use HDF5 files since they are easier to work with in Julia. You can also use TFRecord files, however an implementation is only provided for handling files that are exactly like the ones from the CylinderFlow example.","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"⚠️ The following sections only contain explanations for using HDF5 files.","category":"page"},{"location":"training_data/#Data-File-Structure-(train.h5,-valid.h5,-test.h5)","page":"Training Data","title":"Data File Structure (train.h5, valid.h5, test.h5)","text":"","category":"section"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"Your data files should have the following structure:","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"trajectory_1\nfeaturekey1\nfeaturekey2\n...\ntrajectory_2\nfeaturekey1\nfeaturekey2\n...\n...","category":"page"},{"location":"training_data/#File-for-Metadata-(meta.json)","page":"Training Data","title":"File for Metadata (meta.json)","text":"","category":"section"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"Your metadata file also has to follow a defined structure. Since the metadata file for the CylinderFlow example is handled differently, two files are explained in the following.","category":"page"},{"location":"training_data/#Default-Metadata","page":"Training Data","title":"Default Metadata","text":"","category":"section"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"The default structure that you should use for your metadata is the following (example derived from the CylinderFlow metadata, not an actual metadata file):","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"{\n    \"dt\": \"time\",                               # key inside the HDF5 file for timesteps\n    \"trajectory_length\": 600,                   # length of trajectories (i.e. number of steps) inside data files\n    \"dims\": [                                   # dimensions of the mesh (here a mesh of dimensions (5, 3))\n        5,\n        3\n    ],\n    \"feature_names\": [                          # names of all features, mesh_pos and node_type are required\n        \"mesh_pos\",\n        \"node_type\",\n        \"velocity\"\n    ],\n    \"target_features\": [                        # names of target features (i.e. quantities of interest) as output of the network\n        \"velocity\"\n    ],\n    \"features\": {                               # detailed information of the features given above\n        \"mesh_pos\": {                           # name of the feature given above\n            \"key\": \"cl_mesh[%d,%d].pos\",        # key inside the HDF5 file for the feature, see below\n            \"split\": true,                      # true if your feature is split between multiple keys, false otherwise\n            \"dim\": 2,                           # dimension of the feature\n            \"type\": \"static\",                   # \"static\" if the feature does not change over time, \"dynamic\" otherwise\n            \"dtype\": \"float32\"                  # data type of the feature\n        },\n        \"node_type\": {\n            \"key\": \"cl_mesh[%d,%d].cellType\",\n            \"dim\": 1,\n            \"type\": \"static\",\n            \"dtype\": \"int32\",\n            \"onehot\": true,                     # should the feature be represented as a onehot vector (optional)\n            \"data_min\": 0,                      # minimum value of the feature (optional, required if \"data_max\" specified)\n            \"data_max\": 6                       # maximum value of the feature (optional, required if \"data_min\" specified)\n        },\n        \"velocity\": {\n            \"key\": \"cl_mesh[%d,%d].velocity\",\n            \"dim\": 2,\n            \"type\": \"dynamic\",\n            \"dtype\": \"float32\"\n        }\n    }\n}","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"Here is a detailed description of each possible metadata:","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"Metadata Data type Description\n\"dt\" String each trajectory needs to have an entry for timesteps with the given key\n\"trajectory_length\" Integer each trajectory needs to have the same length i.e. the same amount of steps\n\"dims\" Vector{Integer} dimensions can be 1-, 2- or 3-dimensional\n\"feature_names\" Vector{String} list all features that are also used as an input of the network\n\"target_features\" Vector{String} list all features that the network should predict, they have to be part of \"feature_names\"","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"Each feature has its own metadata:","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"Feature Metadata Data Type Description\n\"key\" String further description of HDF5 key structure  are below\n\"split\" Bool keys are split at the end (e.g. \"cl_mesh[%d,%d].pos[1]\" and \"cl_mesh[%d,%d].pos[2]\")\n\"dim\" Integer dimension of the feature\n\"type\" String \"static\" if the feature does not change over time, \"dynamic\" otherwise\n\"dtype\" String possible datatypes: \"int32\", \"float32\", \"Bool\"\n\"onehot\" Bool can be used if you want to convert types represented as Integer to a onehot vector\n\"data_min\" Float if you specify \"data_min\" and \"data_max\", offline normalization is used, online otherwise\n\"data_max\" Float see \"data_min\"\n\"target_min\" Float equivalent to \"data_min\" and \"data_max\", specifies interval for normalization target\n\"target_max\" Float see \"target_min\"","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"The structure for the HDF5 key has to follow one rule:","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"⚠️ Square brackets are exlusively usedonce for the index of the mesh point (e.g. \"cl_mesh[%d,%d].cellType\") and\nonce at the end of the key if the feature \"split\" is set to true.","category":"page"},{"location":"training_data/#CylinderFlow-Metadata","page":"Training Data","title":"CylinderFlow Metadata","text":"","category":"section"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"The metadata file (taken from the from CylinderFlow example) has the following structure:","category":"page"},{"location":"training_data/","page":"Training Data","title":"Training Data","text":"{\n    \"dt\": 0.01,                     # time delta between steps in the data \n    \"trajectory_length\": 600,       # length of trajectories (i.e. number of steps) inside data files\n    \"n_trajectories\": 1000,         # number of trajectories inside train.h5\n    \"n_trajectories_valid\": 100,    # number of trajectories inside valid.h5\n    \"dims\": 2,                      # dimension of the mesh\n    \"feature_names\": [              # names of all features, mesh_pos and node_type are required\n        \"cells\",\n        \"mesh_pos\",\n        \"node_type\",\n        \"velocity\"\n    ],\n    \"target_features\": [            # names of target features (i.e. quantities of interest) as output of the network\n        \"velocity\"\n    ],\n    \"features\": {                   # detailed information of the features given above\n      \"cells\": {                    # name of the feature given above\n        \"type\": \"static\",           # \"static\" if the feature does not change over time, \"dynamic\" otherwise\n        \"dim\": 3,                   # dimension of the feature\n        \"shape\": [                  # individual dimensions of the feature, one dimension can be inferred from data via -1\n          1,\n          -1,\n          3\n        ],\n        \"dtype\": \"int32\"            # data type of the feature\n      },\n      \"mesh_pos\": {\n        \"type\": \"static\",\n        \"dim\": 2,\n        \"shape\": [\n          1,\n          -1,\n          2\n        ],\n        \"dtype\": \"float32\"\n      },\n      \"node_type\": {\n        \"type\": \"static\",\n        \"dim\": 1,\n        \"shape\": [\n          1,\n          -1,\n          1\n        ],\n        \"dtype\": \"int32\",\n        \"onehot\": true,             # should the feature be represented as a onehot vector (optional)\n        \"data_min\": 0,              # minimum value of the feature (optional, required if \"data_max\" specified)\n        \"data_max\": 6               # maximum value of the feature (optional, required if \"data_min\" specified)\n      },\n      \"velocity\": {\n        \"type\": \"dynamic\",\n        \"dim\": 2,\n        \"shape\": [\n          600,\n          -1,\n          2\n        ],\n        \"dtype\": \"float32\"\n      }\n    }\n  }","category":"page"},{"location":"strategies/#Training-Strategies","page":"Training Strategies","title":"Training Strategies","text":"","category":"section"},{"location":"strategies/","page":"Training Strategies","title":"Training Strategies","text":"Collocation\nRandomCollocation\nSingleShooting\nMultipleShooting","category":"page"},{"location":"strategies/#MeshGraphNets.Collocation","page":"Training Strategies","title":"MeshGraphNets.Collocation","text":"Collocation(;window_size = 0, eigeninformed = false, plot_progress = false)\n\nCompares the prediction of the system with the derivative from the data (via finite differences). Useful for initial training of the system since it it faster than training with a solver.\n\nKeyword Arguments\n\nwindow_size: Number of steps from each trajectory (starting at the beginning) that are used for training. If the number is zero then the whole trajectory is used.\neigeninformed: Whether eigeninformed training is used at each training step or not. See utils.jl for reference.\nplot_progress: Whether the training progress is plotted or not.\n\n\n\n\n\n","category":"type"},{"location":"strategies/#MeshGraphNets.RandomCollocation","page":"Training Strategies","title":"MeshGraphNets.RandomCollocation","text":"RandomCollocation(;window_size = 0, eigeninformed = false, plot_progress = false)\n\nSimilar to Collocation, but timesteps are sampled randomly from the trajectory instead of sequential.\n\nKeyword Arguments\n\nwindow_size: Number of steps from each trajectory (starting at the beginning) that are used for training. If the number is zero then the whole trajectory is used.\neigeninformed: Whether eigeninformed training is used at each training step or not. See utils.jl for reference.\nplot_progress: Whether the training progress is plotted or not.\n\n\n\n\n\n","category":"type"},{"location":"strategies/#MeshGraphNets.SingleShooting","page":"Training Strategies","title":"MeshGraphNets.SingleShooting","text":"SingleShooting(tstart, dt, tstop, solver; sense = InterpolatingAdjoint(autojacvec = ZygoteVJP()), plot_progress = false, solargs...)\n\nThe default solver based training that is normally used for NeuralODEs. Simulates the system from tstart to tstop and calculates the loss based on the difference between the prediction and the ground truth at the timesteps tstart:dt:tstop.\n\nArguments\n\ntstart: Start time of the simulation.\ndt: Interval at which the simulation is saved.\ntstop: Stop time of the simulation.\nsolver: The solver that is used for simulating the system.\n\nKeyword Arguments\n\nsense: The sensitivity algorithm that is used for caluclating the sensitivities.\nplot_progress: Whether the training progress is plotted or not.\nsolargs: Keyword arguments that are passed on to the solver.\n\n\n\n\n\n","category":"type"},{"location":"strategies/#MeshGraphNets.MultipleShooting","page":"Training Strategies","title":"MeshGraphNets.MultipleShooting","text":"MultipleShooting (Prototype, in development)\n\n\n\n\n\n","category":"type"},{"location":"overview/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"overview/","page":"Overview","title":"Overview","text":"This page provides links for the different sections of this documentation. You can start with one of the examples if you want to try out the package or create your own network via MeshGraphNets.jl for your use case.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"References for training strategies and the core package GraphNetCore.jl are also listed.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Getting Started","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Training Data: Overview on how your data for training, evaluating and testing the system should be structured.\nTraining & Evaluation: Overview on how to train and evaluate your network.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Examples","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"CylinderFlow: Example use case provided by Google DeepMind in their corresponding repository.","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Reference","category":"page"},{"location":"overview/","page":"Overview","title":"Overview","text":"Training Strategies: Different training strategies that can be used for training.\nGraphNetCore.jl: Documentation of the core package.","category":"page"},{"location":"train_eval/#Training-and-evaluating-the-system","page":"Training & Evaluation","title":"Training and evaluating the system","text":"","category":"section"},{"location":"train_eval/","page":"Training & Evaluation","title":"Training & Evaluation","text":"train_network\neval_network","category":"page"},{"location":"train_eval/#MeshGraphNets.train_network","page":"Training & Evaluation","title":"MeshGraphNets.train_network","text":"train_network(noise_stddevs, opt, ds_path, cp_path; kws...)\n\nStarts the training process with the given configuration.\n\nArguments\n\nnoise_stddevs: Array containing the noise that is added to the specified node types.\nopt: Optimiser that is used for training.\nds_path: Path to the dataset folder.\ncp_path: Path where checkpoints are being saved to.\nkws: Keyword arguments that customize the training process.\n\nKeyword Arguments\n\nmps = 15: Number of message passing steps.\nlayer_size = 256: Latent size of the hidden layers inside MLPs.\nhidden_layers = 2: Number of hidden layers inside MLPs.\nbatchsize = 1: Size per batch (not implemented yet).\nepochs = 1: Number of epochs.\nsteps = 10e6: Number of training steps.\ncheckpoint = 10000: Number of steps after which checkpoints are created.\nnorm_steps = 1000: Number of steps before training (accumulate normalization stats).\ntypes_updated = [0, 5]: Array containing node types which are updated after each step.\ntypes_noisy = [0]: Array containing node types which noise is added to.\ntraining_strategy = Collocation(): Methods used for training. See \nuse_cuda = true: Whether a GPU is used for training or not (if available). Currently only CUDA GPUs are supported.\ngpu_idx = 0: Index of GPU. See nvidia-smi for reference.\ncell_idxs = [0]: Indices of cells that are plotted during validation (if enabled).\nsolver_valid = Tsit5(): Which solver should be used for validation during training.\nsolver_valid_dt = nothing: If set, the solver for validation will use fixed timesteps.\n\nTraining Strategies\n\nCollocation\nRandomCollocation\nSingleShooting\nMultipleShooting\n\nSee documentation for reference.\n\nReturns\n\nmgn: The trained network as a GraphNetwork struct.\n\n\n\n\n\n","category":"function"},{"location":"train_eval/#MeshGraphNets.eval_network","page":"Training & Evaluation","title":"MeshGraphNets.eval_network","text":"eval_network(ds_path, cp_path, out_path, solver; start, stop, dt, saves, mse_steps, kws...)\n\nStarts the evaluation process with the given configuration.\n\nArguments\n\nds_path: Path to the dataset folder.\ncp_path: Path where checkpoints are being saved to.\nout_path: Path where the result is being saved to.\nsolver: Solver that is used for evaluating the system.\nstart: Start time of the simulation.\nstop: Stop time of the simulation.\ndt = nothing: If provided, changes the solver to use fixed step sizes.\nsaves: Time steps where the solution is saved at.\nmse_steps: Time steps where the relative error is printed at.\nkws: Keyword arguments that customize the training process. The configuration of the system has to be the same as during training.\n\nKeyword Arguments\n\nmps = 15: Number of message passing steps.\nlayer_size = 256: Latent size of the hidden layers inside MLPs.\nhidden_layers = 2: Number of hidden layers inside MLPs.\ntypes_updated = [0, 5]: Array containing node types which are updated after each step.\nuse_cuda = true: Whether a GPU is used for training or not (if available). Currently only CUDA GPUs are supported.\ngpu_idx = 0: Index of GPU. See nvidia-smi for reference.\nnum_rollouts = 10: Number of trajectories that are simulated (from the test dataset).\n\n\n\n\n\n","category":"function"},{"location":"cylinder_flow/#CylinderFlow-by-Google-DeepMind","page":"CylinderFlow","title":"CylinderFlow by Google DeepMind","text":"","category":"section"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"This examples provides information on preparing the data for the CylinderFlow example provided by Google DeepMind in their corresponding repository an how you can train and evaluate the resulting network.","category":"page"},{"location":"cylinder_flow/#Data-Preparation","page":"CylinderFlow","title":"Data Preparation","text":"","category":"section"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"First you need to download the provided datasets for training, evaluation and testing. An explanation on how you can download the files is provided in the repository:","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"https://github.com/google-deepmind/deepmind-research/tree/master/meshgraphnets#datasets","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"If you execute the file download_dataset.sh with the argument cylinder_flow the following files should download:","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"meta.json\ntrain.tfrecord\nvalid.tfrecord\ntest.tfrecord","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"You can keep the .tfrecord files as is. You only need to change the meta.json file to be compatible with MeshGraphNets.jl. The correct file is provided in the examples folder and you only need to copy it to the same folder as the .tfrecord files.","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"If you want to understand the structure of the meta.json file take a look at the section Training Data.","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"The default path for the data folder that is specified in the example script is:","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"{path_to_cylinder_flow.jl}/data/datasets/","category":"page"},{"location":"cylinder_flow/#Training-the-Network","page":"CylinderFlow","title":"Training the Network","text":"","category":"section"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"In order to train the system you can simply comment in/out the lines of code provided in the script:","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"#################\n# Train network #\n#################\n\n# with Collocation\n\ntrain_network(\n    noise, opt, ds_path, chk_path; mps = message_steps, layer_size = layer_size, hidden_layers = hidden_layers, batchsize = batch,\n    epochs = epo, steps = Int(ns), use_cuda = cuda, checkpoint = cp, norm_steps = 1000, types_updated = types_updated,\n    types_noisy = types_noisy, training_strategy = Collocation(), solver_valid = Euler(), solver_valid_dt = 0.01f0\n)\n\n# with SingleShooting\n\ntrain_network(\n    noise, opt, ds_path, chk_path; mps = message_steps, layer_size = layer_size, hidden_layers = hidden_layers, batchsize = batch, epochs = epo,\n    steps = Int(ns), use_cuda = cuda, checkpoint = 10, norm_steps = 1000, types_updated = types_updated, types_noisy = types_noisy,\n    training_strategy = SingleShooting(0.0f0, 0.01f0, 5.99f0, Euler(); adaptive = false, tstops = 0.0f0:0.01f0:5.99f0)\n)","category":"page"},{"location":"cylinder_flow/#Evaluating-the-Trained-Network","page":"CylinderFlow","title":"Evaluating the Trained Network","text":"","category":"section"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"The same applies to evaluating the system. Simply comment in/out the desired lines of code:","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"####################\n# Evaluate network #\n####################\n\n# with Euler (fixed timestep)\n\neval_network(\n    ds_path, chk_path, eval_path, Euler(); start = 0.0f0, stop = 5.99f0, dt = 0.01f0, saves = 0.0f0:0.01f0:5.99f0,\n    mse_steps = collect(0.0f0:1.0f0:5.99f0), mps = message_steps, layer_size = layer_size, hidden_layers = hidden_layers, use_cuda=cuda\n)\n\n# with Tsit5 (adaptive timestep)\n\neval_network(\n    ds_path, chk_path, eval_path, Tsit5(); start = 0.0f0, stop = 5.99f0, saves = 0.0f0:0.01f0:5.99f0,\n    mse_steps = collect(0.0f0:1.0f0:5.99f0), mps = message_steps, layer_size = layer_size, hidden_layers = hidden_layers, use_cuda=cuda\n)\n","category":"page"},{"location":"cylinder_flow/#Addition:-Arguments-for-Training-and-Evaluation","page":"CylinderFlow","title":"Addition: Arguments for Training & Evaluation","text":"","category":"section"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"The arguments provided at the top of the example script and in the function call correspond to the default values that were used by DeepMind. You can change them to see how that affects runtime and accuracy of the network.","category":"page"},{"location":"cylinder_flow/","page":"CylinderFlow","title":"CylinderFlow","text":"The arguments inside the function calls can also be modified. An explanation can be found in section Training & Evaluation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: MeshGraphNets.jl Logo)","category":"page"},{"location":"#MeshGraphNets.jl","page":"Home","title":"MeshGraphNets.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: Docs)","category":"page"},{"location":"","page":"Home","title":"Home","text":"MeshGraphNets.jl is a software package for the Julia programming language that provides an implementation of the MeshGraphNets framework by Google DeepMind for simulating mesh-based physical systems via graph neural networks:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, and Peter W. Battaglia. 2021. Learning Mesh-Based Simulation with Graph Networks. In International Conference on Learning Representations.","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can find the original implementation of MeshGraphNets in their GitHub repository here.","category":"page"},{"location":"#Overwiev","page":"Home","title":"Overwiev","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"MeshGraphNets.jl is designed to be part of the SciML ecosystem. The original framework was remodeled into a NeuralODE so that solvers from the DifferentialEquations.jl can be used to evaluate the system.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Base functionality for the Encode-Process-Decode architecture of DeepMind that MeshGraphNets is based on is provided in the core package GraphNetCore.jl.","category":"page"},{"location":"#How-to-use-MeshGraphNets.jl","page":"Home","title":"How to use MeshGraphNets.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Examples from the original paper are implemented in the examples folder. You can also refer to the documentation if you want to model your own system.","category":"page"},{"location":"#Currently-Supported","page":"Home","title":"Currently Supported","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Customizable input & output quantities\n1D & 3D meshes\nNode features & Edge features\nDifferent strategies for training (see here)\nEvaluation of system with DifferentialEquations.jl solvers","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Coming soon!","category":"page"},{"location":"graph_net_core/#GraphNetCore.jl-Documentation","page":"GraphNetCore.jl","title":"GraphNetCore.jl Documentation","text":"","category":"section"},{"location":"graph_net_core/#GraphNetwork","page":"GraphNetCore.jl","title":"GraphNetwork","text":"","category":"section"},{"location":"graph_net_core/","page":"GraphNetCore.jl","title":"GraphNetCore.jl","text":"GraphNetwork\nbuild_model\nstep!\nsave!\nload","category":"page"},{"location":"graph_net_core/#GraphNetCore.GraphNetwork","page":"GraphNetCore.jl","title":"GraphNetCore.GraphNetwork","text":"GraphNetwork(model, ps, st, e_norm, n_norm, o_norm)\n\nThe central data structure that contains the neural network and the normalisers corresponding to the components of the GNN (edge features, node features and output).\n\nArguments\n\nmodel: The Enocde-Process-Decode model as a Lux Chain.\nps: Parameters of the model.\nst: State of the model.\ne_norm: Normaliser for the edge features of the GNN.\nn_norm: Normaliser for the node features of the GNN, whereas each feature has its own normaliser.\no_norm: Normaliser for the output of the GNN.\n\n\n\n\n\n","category":"type"},{"location":"graph_net_core/#GraphNetCore.build_model","page":"GraphNetCore.jl","title":"GraphNetCore.build_model","text":"build_model(quantities_size::Integer, dims, output_size::Integer, mps::Integer, layer_size::Integer, hidden_layers::Integer, device::Function)\n\nConstructs the Encode-Process-Decode model as a Lux Chain with the given arguments.\n\nArguments\n\nquantities_size: Sum of dimensions of each node feature.\ndims: Dimension of the mesh.\noutput_size: Sum of dimensions of output quantities.\nmps: Number of message passing steps.\nlayer_size: Size of hidden layers.\nhidden_layers: Number of hidden layers.\ndevice: Device where the model should be loaded (see Lux GPU Management).\n\nReturns\n\nmodel: The Encode-Process-Decode model as a Lux Chain.\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#GraphNetCore.step!","page":"GraphNetCore.jl","title":"GraphNetCore.step!","text":"step!(gn, graph, target_quantities_change, mask, loss_function)\n\nArguments\n\ngn: The used GraphNetwork.\ngraph: Input data stored in a FeatureGraph.\ntarget_quantities_change: Derivatives of quantities of interest (e.g. via finite differences from data).\nmask: Mask for excluding node types that should not be updated.\nloss_function: Loss function that is used to calculate the error.\n\nReturns\n\ngs: The calculated gradients.\ntrain_loss: The calculated training loss.\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#GraphNetCore.save!","page":"GraphNetCore.jl","title":"GraphNetCore.save!","text":"save!(gn, opt_state, df_train::DataFrame, df_valid::DataFrame, step::Integer, train_loss::Float32, path::String; is_training = true)\n\nCreates a checkpoint of the GraphNetwork at the given training step.\n\nArguments\n\ngn: The GraphNetwork that a checkpoint is created of.\nopt_state: State of the optimiser.\ndf_train: DataFrames.jl DataFrame that stores the train losses at the checkpoints.\ndf_valid: DataFrames.jl DataFrame that stores the validation losses at the checkpoints (only improvements are saved).\nstep: Current training step where the checkpoint is created.\ntrain_loss: Current training loss.\npath: Path to the folder where checkpoints are saved.\n\nKeyword Arguments\n\nis_training = true: True if used in training, false otherwise (in validation).\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#FileIO.load","page":"GraphNetCore.jl","title":"FileIO.load","text":"load(quantities, dims, norms, output, message_steps, ls, hl, opt, device::Function, path::String)\n\nLoads the GraphNetwork from the latest checkpoint at the given path. \n\nArguments\n\nquantities: Sum of dimensions of each node feature.\ndims: Dimension of the mesh.\nnorms: Normalisers for node features.\noutput: Sum of dimensions of output quantities.\nmessage_steps: Number of message passing steps.\nls: Size of hidden layers.\nhl: Number of hidden layers.\nopt: Optimiser that is used for training. Set this to nothing if you want to use the optimiser from the checkpoint.\ndevice: Device where the model should be loaded (see Lux GPU Management).\npath: Path to the folder where the checkpoint is.\n\nReturns\n\ngn: The loaded GraphNetwork from the checkpoint.\nopt_state: The loaded optimiser state. Is nothing if no checkpoint was found or an optimiser was passed as an argument.\ndf_train: DataFrames.jl DataFrame containing the train losses at the checkpoints.\ndf_valid: DataFrames.jl DataFrame containing the validation losses at the checkpoints (only improvements are saved).\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#FeatureGraph","page":"GraphNetCore.jl","title":"FeatureGraph","text":"","category":"section"},{"location":"graph_net_core/","page":"GraphNetCore.jl","title":"GraphNetCore.jl","text":"FeatureGraph","category":"page"},{"location":"graph_net_core/#GraphNetCore.FeatureGraph","page":"GraphNetCore.jl","title":"GraphNetCore.FeatureGraph","text":"FeatureGraph(nf, ef, senders, receivers)\n\nData structure that is used as an input for the GraphNetwork.\n\nArguments\n\nnf: Node features of the graph.\nef: edge features of the graph.\nsenders: List of nodes in the mesh where graph edges start.\nreceivers: List of nodes in the mesh where graph edges end.\n\n\n\n\n\n","category":"type"},{"location":"graph_net_core/#Normaliser","page":"GraphNetCore.jl","title":"Normaliser","text":"","category":"section"},{"location":"graph_net_core/","page":"GraphNetCore.jl","title":"GraphNetCore.jl","text":"NormaliserOffline\nNormaliserOnline\ninverse_data","category":"page"},{"location":"graph_net_core/#GraphNetCore.NormaliserOffline","page":"GraphNetCore.jl","title":"GraphNetCore.NormaliserOffline","text":"NormaliserOffline(data_min::Float32, data_max::Float32, target_min::Float32 = 0.0f0, target_max::Float32 = 0.0f0)\n\nOffline normalization if the minimum and maximum of the quantity is known (e.g. from the training data). It is recommended to use offline normalization since the minimum and maximum do not need to be inferred from data.\n\nArguments\n\ndata_min: Minimum of the quantity in the dataset.\ndata_max: Maximum of the quantity in the dataset.\ntarget_min: Minimum of the target of normalization.\ntarget_max: Maximum of the target of normalization.\n\n\n\n\n\n","category":"type"},{"location":"graph_net_core/#GraphNetCore.NormaliserOnline","page":"GraphNetCore.jl","title":"GraphNetCore.NormaliserOnline","text":"NormaliserOnline(max_accumulations::Float32, std_epsilon::Float32, acc_count::Float32, num_accumulations::Float32, acc_sum::AbstractArray{Float32}, acc_sum_squared::AbstractArray{Float32})\n\nOnline normalization if the minimum and maximum of the quantity is not known. It is recommended to use offline normalization since the minimum and maximum do not need to be inferred from data.\n\nArguments\n\nmax_accumulations: Maximum number of accumulation steps.\nstd_epsilon: Epsilon for caluclating the standard deviation.\nacc_count: Sum of dimensions of quantities in each accumulation step.\nnum_accumulations: Current number of accumulation steps.\nacc_sum: Sum of quantities in each step.\nacc_sum_squared: Sum of quantities squared in each step.\n\n\n\n\n\n","category":"type"},{"location":"graph_net_core/#GraphNetCore.inverse_data","page":"GraphNetCore.jl","title":"GraphNetCore.inverse_data","text":"inverse_data(n::NormaliserOffline, data)\n\nInverses the normalised data.\n\nArguments\n\nn: The used NormaliserOffline.\ndata: Data to be converted back.\n\nReturns\n\nThe converted data.\n\n\n\n\n\ninverse_data(n::NormaliserOnline, data)\n\nInverses the normalised data.\n\nArguments\n\nn: The used NormaliserOnline.\ndata: Data to be converted back.\n\nReturns\n\nThe converted data.\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#Utilities","page":"GraphNetCore.jl","title":"Utilities","text":"","category":"section"},{"location":"graph_net_core/","page":"GraphNetCore.jl","title":"GraphNetCore.jl","text":"triangles_to_edges\nparse_edges\none_hot\nminmaxnorm\nmse_reduce","category":"page"},{"location":"graph_net_core/#GraphNetCore.triangles_to_edges","page":"GraphNetCore.jl","title":"GraphNetCore.triangles_to_edges","text":"triangles_to_edges(faces::AbstractArray{T, 2} where T <: Integer)\n\nConverts the given faces of a mesh to edges.\n\nArguments\n\nfaces: Two-dimensional array with the node indices in the first dimension.\n\nReturns\n\nA tuple containing the edge pairs. (See parse_edges)\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#GraphNetCore.parse_edges","page":"GraphNetCore.jl","title":"GraphNetCore.parse_edges","text":"parse_edges(edges)\n\nConverts the given edges to unique pairs of senders and receivers (in both directions).\n\nArguments\n\nedges: A two-dimensional Array containing the edges. The first dimension represents a sender-receiver pair.\n\nReturns\n\nA tuple containing the bi-directional sender-receiver pairs. The first index is one direction, the second index the other one.\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#GraphNetCore.one_hot","page":"GraphNetCore.jl","title":"GraphNetCore.one_hot","text":"one_hot(indices, depth, offset = 0)\n\nConstructs a onehot matrix of Bool with the given indices.\n\nArguments\n\nindices: Indices for the onehot matrix.\ndepth: Depth of the matrix. The second dimension will be clipped or padded with zeros to the depth.\noffset = 0: Offset of the matrix in the second dimension.\n\nReturns\n\nresult: The onehot matrix from the given arguments.\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#GraphNetCore.minmaxnorm","page":"GraphNetCore.jl","title":"GraphNetCore.minmaxnorm","text":"minmaxnorm(input::AbstractArray, input_min, input_max, new_min = 0.0f0, new_max = 1.0f0)\n\nNormalizes the given input to the new given range.\n\nArguments\n\ninput: Data that should be normalized.\ninput_min: Minimum of the given data.\ninput_max: Maximum of the given data.\nnew_min = 0.0f0: New minimum of the normalized data.\nnew_max = 1.0f0: New maximum of the normalized data.\n\nReturns\n\nThe normalized data.\n\n\n\n\n\n","category":"function"},{"location":"graph_net_core/#GraphNetCore.mse_reduce","page":"GraphNetCore.jl","title":"GraphNetCore.mse_reduce","text":"mse_reduce(target, output)\n\nCalculates the mean squared error of the given arguments with Tullio for GPU compatibility.\n\nArguments\n\ntarget: Ground truth from the data.\noutput: Output of the network.\n\nReturns\n\nThe calculated mean squared error.\n\n\n\n\n\n","category":"function"}]
}
